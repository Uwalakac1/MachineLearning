{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f3faaee",
   "metadata": {},
   "source": [
    "# HW 8 Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a69b92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6c5550",
   "metadata": {},
   "source": [
    "Part 1: Explain Laplace smoothing: \n",
    "A techinque used to address the issue of zero probabilities in categorical data, particularly when estimating probabilities from a limited set of observations. The problem arises when you are trying to estimate the probability of an event that has not been observed in your dataset. In such cases, traditional maximum likelihood estimation might assign a probability of zero, which can lead to problems when dealing with subsequent calculations, such as in the case of Bayesian inference.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54867be8",
   "metadata": {},
   "source": [
    "Part II: Build a Na¨ıve Bayes algorithm on the titanic data set attached to OneDrive to\n",
    "predict whether a passenger survived or not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116f92f5",
   "metadata": {},
   "source": [
    "1. Import the data set into pandas data frame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3f7d6c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330877</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Palsson, Master. Gosta Leonard</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>347742</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>237736</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "5            6         0       3   \n",
       "6            7         0       1   \n",
       "7            8         0       3   \n",
       "8            9         1       3   \n",
       "9           10         1       2   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "5                                   Moran, Mr. James    male   NaN      0   \n",
       "6                            McCarthy, Mr. Timothy J    male  54.0      0   \n",
       "7                     Palsson, Master. Gosta Leonard    male   2.0      3   \n",
       "8  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female  27.0      0   \n",
       "9                Nasser, Mrs. Nicholas (Adele Achem)  female  14.0      1   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  \n",
       "5      0            330877   8.4583   NaN        Q  \n",
       "6      0             17463  51.8625   E46        S  \n",
       "7      1            349909  21.0750   NaN        S  \n",
       "8      2            347742  11.1333   NaN        S  \n",
       "9      0            237736  30.0708   NaN        C  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"titanic.csv\")\n",
    "titanic=pd.DataFrame(df)\n",
    "titanic.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0b5c6e",
   "metadata": {},
   "source": [
    "2. Split the data into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d46d0b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = titanic.drop(columns=[\"Survived\"])\n",
    "y = titanic[\"Survived\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3aa15468",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266c0aaa",
   "metadata": {},
   "source": [
    "3. Select one or more explanatory variables you would like to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c211991d",
   "metadata": {},
   "outputs": [],
   "source": [
    "explanatory_variables = titanic[[\"Age\", \"Sex\", \"Pclass\", \"Parch\", \"Fare\", \"Embarked\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e7633b",
   "metadata": {},
   "source": [
    "4. Figure out if there are any missing values in the explanatory variables you want to use and either delete those passengers from the data set or fill in the missing values. If a numerical variable has missing values, you might fill those in with the average or median of that variable. If a categorical variable has missing values, you might fill those in using the most common value. You can create your own script for missing values or your can use sklearn SimpleImputer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "352de3eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing values:\n",
      " Age         177\n",
      "Sex           0\n",
      "Pclass        0\n",
      "Parch         0\n",
      "Fare          0\n",
      "Embarked      2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_values=explanatory_variables.isnull().sum()\n",
    "print(\"missing values:\\n\", missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6e4daf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing Values After Imputation:\n",
      " Age         0\n",
      "Sex         0\n",
      "Pclass      0\n",
      "Parch       0\n",
      "Fare        0\n",
      "Embarked    0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_46524\\2628404541.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  explanatory_variables[[\"Age\", \"Fare\"]] = numerical_impute.fit_transform(explanatory_variables[[\"Age\", \"Fare\"]])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_46524\\2628404541.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  explanatory_variables[[\"Sex\", \"Embarked\"]] = cat_impute.fit_transform(explanatory_variables[[\"Sex\", \"Embarked\"]])\n"
     ]
    }
   ],
   "source": [
    "numerical_impute=SimpleImputer(strategy=\"mean\")\n",
    "explanatory_variables[[\"Age\", \"Fare\"]] = numerical_impute.fit_transform(explanatory_variables[[\"Age\", \"Fare\"]])\n",
    "\n",
    "cat_impute=SimpleImputer(strategy=\"most_frequent\")\n",
    "explanatory_variables[[\"Sex\", \"Embarked\"]] = cat_impute.fit_transform(explanatory_variables[[\"Sex\", \"Embarked\"]])\n",
    "\n",
    "after_imputation = explanatory_variables.isnull().sum()\n",
    "print(\"\\nMissing Values After Imputation:\\n\", after_imputation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a3a22a",
   "metadata": {},
   "source": [
    "5. Convert the categorical variables to numerical using encoding. You can create your own script or use sklearn LabelEncoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9be1d493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values before encoding:\n",
      "         Sex Embarked\n",
      "0      male        S\n",
      "1    female        C\n",
      "2    female        S\n",
      "3    female        S\n",
      "4      male        S\n",
      "..      ...      ...\n",
      "886    male        S\n",
      "887  female        S\n",
      "888  female        S\n",
      "889    male        C\n",
      "890    male        Q\n",
      "\n",
      "[891 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique values before encoding:\\n\", explanatory_variables[[\"Sex\", \"Embarked\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ae565b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique values after encoding:\n",
      "      Sex  Embarked\n",
      "0      1         2\n",
      "1      0         0\n",
      "2      0         2\n",
      "3      0         2\n",
      "4      1         2\n",
      "..   ...       ...\n",
      "886    1         2\n",
      "887    0         2\n",
      "888    0         2\n",
      "889    1         0\n",
      "890    1         1\n",
      "\n",
      "[891 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_46524\\3387429089.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  explanatory_variables['Sex']=le.fit_transform(explanatory_variables['Sex'])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_46524\\3387429089.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  explanatory_variables['Embarked']=le.fit_transform(explanatory_variables['Embarked'])\n"
     ]
    }
   ],
   "source": [
    "#?LabelEncoder\n",
    "le=LabelEncoder()\n",
    "explanatory_variables['Sex']=le.fit_transform(explanatory_variables['Sex'])\n",
    "explanatory_variables['Embarked']=le.fit_transform(explanatory_variables['Embarked'])\n",
    "#Quick Check\n",
    "print(\"\\nUnique values after encoding:\\n\", explanatory_variables[[\"Sex\", \"Embarked\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57066260",
   "metadata": {},
   "source": [
    "6. Build a model on the training data. You can create your own code or use sklearn NaiveBayes. If you use a mix of continuous and categorical explanatory variables, think of how you can build the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e988c9bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(explanatory_variables, y, test_size=0.3, random_state=42)\n",
    "NB=GaussianNB()\n",
    "NB.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e54671",
   "metadata": {},
   "source": [
    "7. Inspect the evaluation measures (accuracy score, confusion matrix, classification report)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd7a9a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7873134328358209\n",
      "\n",
      "Confusion Matrix:\n",
      " [[131  26]\n",
      " [ 31  80]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82       157\n",
      "           1       0.75      0.72      0.74       111\n",
      "\n",
      "    accuracy                           0.79       268\n",
      "   macro avg       0.78      0.78      0.78       268\n",
      "weighted avg       0.79      0.79      0.79       268\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred=NB.predict(X_test)\n",
    "#Accuracy Score\n",
    "print(\"Accuracy:\", accuracy_score(y_pred, y_test))\n",
    "\n",
    "#Confusion Matrix\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "#Classification Report\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af900b86",
   "metadata": {},
   "source": [
    "8. Take some values for the explanatory variables and use your model to predict if that person would have survived or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c3bbd1ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The person is predicted to have survived.\n",
      "This is similar to laplace smoothing in a sense, since the newdata has not occured in the titanic dataset.\n"
     ]
    }
   ],
   "source": [
    "# Assume you have a set of values for explanatory variables\n",
    "new_data = pd.DataFrame({\n",
    "    \"Age\": [25],\n",
    "    \"Sex\": [\"female\"],\n",
    "    \"Pclass\": [2],\n",
    "    \"Parch\": [0],\n",
    "    \"Fare\": [30],\n",
    "    \"Embarked\": [\"S\"]\n",
    "})\n",
    "\n",
    "\n",
    "new_data[\"Sex\"] = le.fit_transform(new_data[\"Sex\"])\n",
    "new_data[\"Embarked\"] = le.fit_transform(new_data[\"Embarked\"])\n",
    "\n",
    "cat_impute = SimpleImputer(strategy=\"most_frequent\")\n",
    "new_data[[\"Sex\", \"Embarked\"]] = cat_impute.fit_transform(new_data[[\"Sex\", \"Embarked\"]])\n",
    "\n",
    "# Make predictions using the trained model\n",
    "predictions = NB.predict(new_data)\n",
    "\n",
    "# Interpret the predictions\n",
    "if predictions[0] == 0:\n",
    "    print(\"The person is predicted to not have survived.\")\n",
    "else:\n",
    "    print(\"The person is predicted to have survived.\")\n",
    "\n",
    "print(\"This is similar to laplace smoothing in a sense, since the newdata has not occured in the titanic dataset.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
