{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da1215dc",
   "metadata": {},
   "source": [
    "# Data 4319: HW 1\n",
    "## Chiagozie Uwalaka"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb53e88d",
   "metadata": {},
   "source": [
    "A. We mentioned that perceptron converges if the data is linearly separable. Try sklearn perceptron model for versicolor and virginica, with sepal length and petal length. What do you observe? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cd2d03f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>7.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>6.5</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.5</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width     species\n",
       "50            7.0          3.2           4.7          1.4  versicolor\n",
       "51            6.4          3.2           4.5          1.5  versicolor\n",
       "52            6.9          3.1           4.9          1.5  versicolor\n",
       "53            5.5          2.3           4.0          1.3  versicolor\n",
       "54            6.5          2.8           4.6          1.5  versicolor\n",
       "..            ...          ...           ...          ...         ...\n",
       "145           6.7          3.0           5.2          2.3   virginica\n",
       "146           6.3          2.5           5.0          1.9   virginica\n",
       "147           6.5          3.0           5.2          2.0   virginica\n",
       "148           6.2          3.4           5.4          2.3   virginica\n",
       "149           5.9          3.0           5.1          1.8   virginica\n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mlxtend.plotting\n",
    "\n",
    "# Import a function for plotting decision boudaries\n",
    "# !pip install mlxtend\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "df = pd.read_csv(\"iris_dataset.csv\")\n",
    "df = df.iloc[50:150]\n",
    "x = df[[\"sepal_length\", \"petal_length\"]]\n",
    "\n",
    "x\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8678c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(X)\n",
    "# len(y)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80b7ac1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['species']\n",
    "\n",
    "y = np.where(y == 'virginica', -1, 1)\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82dd1497",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but Perceptron was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Instantiate one instance of the Perceptron class\n",
    "from sklearn.linear_model import Perceptron\n",
    "clf = Perceptron()\n",
    "\n",
    "# Fit the model to the training data\n",
    "clf.fit(x, y)\n",
    "\n",
    "y_pred = clf.predict(x)\n",
    "y_pred\n",
    "\n",
    "plt.figure(figsize = (8, 6))\n",
    "plot_decision_regions(x.to_numpy(), y, clf = clf)\n",
    "plt.title(\"Sklearn Perceptron\", fontsize = 18)\n",
    "plt.xlabel(\"sepal length\", fontsize = 15)\n",
    "plt.ylabel(\"petal length\", fontsize = 15);\n",
    "\n",
    "\n",
    "#As shown in the graph below our graph is not linearly seperable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f99121",
   "metadata": {},
   "source": [
    "(b) We created My_Perceptron class for only 2 inputs. Extend this code for 3 inputs. Investigate the iris data set and choose 3 features to classify setosa and versicolor using your code. Notice that you cannot easily plot the decision boundary now since the data is 3-dimensional, but you can still compare the actual and the predicted labels to see how your algorithm is performing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4302c34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>6.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>7.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2.1</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.9</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>2.2</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>7.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>2.1</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>7.3</td>\n",
       "      <td>2.9</td>\n",
       "      <td>6.3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>6.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.6</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.3</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>6.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>2.1</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.4</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.3</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>7.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2.2</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2.6</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>5.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.1</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>6.2</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>6.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.1</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1.6</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>7.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>7.9</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>7.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>6.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.1</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>6.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width    species\n",
       "100           6.3          3.3           6.0          2.5  virginica\n",
       "101           5.8          2.7           5.1          1.9  virginica\n",
       "102           7.1          3.0           5.9          2.1  virginica\n",
       "103           6.3          2.9           5.6          1.8  virginica\n",
       "104           6.5          3.0           5.8          2.2  virginica\n",
       "105           7.6          3.0           6.6          2.1  virginica\n",
       "106           4.9          2.5           4.5          1.7  virginica\n",
       "107           7.3          2.9           6.3          1.8  virginica\n",
       "108           6.7          2.5           5.8          1.8  virginica\n",
       "109           7.2          3.6           6.1          2.5  virginica\n",
       "110           6.5          3.2           5.1          2.0  virginica\n",
       "111           6.4          2.7           5.3          1.9  virginica\n",
       "112           6.8          3.0           5.5          2.1  virginica\n",
       "113           5.7          2.5           5.0          2.0  virginica\n",
       "114           5.8          2.8           5.1          2.4  virginica\n",
       "115           6.4          3.2           5.3          2.3  virginica\n",
       "116           6.5          3.0           5.5          1.8  virginica\n",
       "117           7.7          3.8           6.7          2.2  virginica\n",
       "118           7.7          2.6           6.9          2.3  virginica\n",
       "119           6.0          2.2           5.0          1.5  virginica\n",
       "120           6.9          3.2           5.7          2.3  virginica\n",
       "121           5.6          2.8           4.9          2.0  virginica\n",
       "122           7.7          2.8           6.7          2.0  virginica\n",
       "123           6.3          2.7           4.9          1.8  virginica\n",
       "124           6.7          3.3           5.7          2.1  virginica\n",
       "125           7.2          3.2           6.0          1.8  virginica\n",
       "126           6.2          2.8           4.8          1.8  virginica\n",
       "127           6.1          3.0           4.9          1.8  virginica\n",
       "128           6.4          2.8           5.6          2.1  virginica\n",
       "129           7.2          3.0           5.8          1.6  virginica\n",
       "130           7.4          2.8           6.1          1.9  virginica\n",
       "131           7.9          3.8           6.4          2.0  virginica\n",
       "132           6.4          2.8           5.6          2.2  virginica\n",
       "133           6.3          2.8           5.1          1.5  virginica\n",
       "134           6.1          2.6           5.6          1.4  virginica\n",
       "135           7.7          3.0           6.1          2.3  virginica\n",
       "136           6.3          3.4           5.6          2.4  virginica\n",
       "137           6.4          3.1           5.5          1.8  virginica\n",
       "138           6.0          3.0           4.8          1.8  virginica\n",
       "139           6.9          3.1           5.4          2.1  virginica\n",
       "140           6.7          3.1           5.6          2.4  virginica\n",
       "141           6.9          3.1           5.1          2.3  virginica\n",
       "142           5.8          2.7           5.1          1.9  virginica\n",
       "143           6.8          3.2           5.9          2.3  virginica\n",
       "144           6.7          3.3           5.7          2.5  virginica\n",
       "145           6.7          3.0           5.2          2.3  virginica\n",
       "146           6.3          2.5           5.0          1.9  virginica\n",
       "147           6.5          3.0           5.2          2.0  virginica\n",
       "148           6.2          3.4           5.4          2.3  virginica\n",
       "149           5.9          3.0           5.1          1.8  virginica"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.iloc[50:150]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c65a5df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.3, 6. , 3.3],\n",
       "       [5.8, 5.1, 2.7],\n",
       "       [7.1, 5.9, 3. ],\n",
       "       [6.3, 5.6, 2.9],\n",
       "       [6.5, 5.8, 3. ],\n",
       "       [7.6, 6.6, 3. ],\n",
       "       [4.9, 4.5, 2.5],\n",
       "       [7.3, 6.3, 2.9],\n",
       "       [6.7, 5.8, 2.5],\n",
       "       [7.2, 6.1, 3.6],\n",
       "       [6.5, 5.1, 3.2],\n",
       "       [6.4, 5.3, 2.7],\n",
       "       [6.8, 5.5, 3. ],\n",
       "       [5.7, 5. , 2.5],\n",
       "       [5.8, 5.1, 2.8],\n",
       "       [6.4, 5.3, 3.2],\n",
       "       [6.5, 5.5, 3. ],\n",
       "       [7.7, 6.7, 3.8],\n",
       "       [7.7, 6.9, 2.6],\n",
       "       [6. , 5. , 2.2],\n",
       "       [6.9, 5.7, 3.2],\n",
       "       [5.6, 4.9, 2.8],\n",
       "       [7.7, 6.7, 2.8],\n",
       "       [6.3, 4.9, 2.7],\n",
       "       [6.7, 5.7, 3.3],\n",
       "       [7.2, 6. , 3.2],\n",
       "       [6.2, 4.8, 2.8],\n",
       "       [6.1, 4.9, 3. ],\n",
       "       [6.4, 5.6, 2.8],\n",
       "       [7.2, 5.8, 3. ],\n",
       "       [7.4, 6.1, 2.8],\n",
       "       [7.9, 6.4, 3.8],\n",
       "       [6.4, 5.6, 2.8],\n",
       "       [6.3, 5.1, 2.8],\n",
       "       [6.1, 5.6, 2.6],\n",
       "       [7.7, 6.1, 3. ],\n",
       "       [6.3, 5.6, 3.4],\n",
       "       [6.4, 5.5, 3.1],\n",
       "       [6. , 4.8, 3. ],\n",
       "       [6.9, 5.4, 3.1],\n",
       "       [6.7, 5.6, 3.1],\n",
       "       [6.9, 5.1, 3.1],\n",
       "       [5.8, 5.1, 2.7],\n",
       "       [6.8, 5.9, 3.2],\n",
       "       [6.7, 5.7, 3.3],\n",
       "       [6.7, 5.2, 3. ],\n",
       "       [6.3, 5. , 2.5],\n",
       "       [6.5, 5.2, 3. ],\n",
       "       [6.2, 5.4, 3.4],\n",
       "       [5.9, 5.1, 3. ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df[[\"sepal_length\", \"petal_length\", \"sepal_width\"]].to_numpy()\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f11b015",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class MyPerceptron(object):\n",
    "    def __init__(self, eta = 0.5, epochs = 50): # epochs is iteration\n",
    "        self.eta = eta\n",
    "        self.epochs = epochs\n",
    "        \n",
    "    def fit(self, x, y): # x=input value, y=output\n",
    "        self.w1 = np.random.rand(1)  #initializing our weights\n",
    "        self.w2 = np.random.rand(1)\n",
    "        self.w3 = np.random.rand(1)\n",
    "        self.b = np.random.rand(1)\n",
    "        \n",
    "        self.errors = []\n",
    "        \n",
    "        for _ in range(self.epochs):\n",
    "            errors = 0\n",
    "            for xi, yi in zip(x, y): \n",
    "                update = self.eta * (self.predict(xi) - yi)\n",
    "                self.w1 = self.w1 - update*xi[0] #x1 \n",
    "                self.w2 = self.w2 - update*xi[1] #x2\n",
    "                self.w3 = self.w3 - update*xi[2] #x3 \n",
    "                self.b = self.b - update\n",
    "                errors = errors + int(update != 0)\n",
    "            if errors == 0:\n",
    "                return self\n",
    "            else:\n",
    "                self.errors.append(errors)\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    def weighted_sum(self, x):\n",
    "        self.w = np.array([self.w1, self.w2, self.w3])\n",
    "        return np.dot(x, self.w) + self.b\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return np.where(self.weighted_sum(x) > 0.0, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73727ea3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.81936653])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.rand(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35186e35",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_clf = MyPerceptron()\n",
    "\n",
    "# Call the fit method \n",
    "my_clf.fit(x, y)\n",
    "\n",
    "y_pred = my_clf.predict(x)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b3b9e9",
   "metadata": {},
   "source": [
    "(c) Try to generalize My_Perceptron code so it could be used for any number of inputs. (Hint: Recall, that for a list w we can use w[-1] and w[:-1] to access the last value in the list and all the values expect the very last value. Also, use np.dot, NumPy dot product, to compute the pre-activation value of  𝑧\n",
    " .)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39043591",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyPerceptron(object):\n",
    "    def __init__(self, eta=0.1, epochs=50):\n",
    "        self.eta = eta\n",
    "        self.epochs = epochs\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        num_features = x.shape[1]\n",
    "        self.w = np.random.rand(num_features)\n",
    "        self.b = np.random.rand(1)\n",
    "        self.errors = []\n",
    "\n",
    "        for _ in range(self.epochs):\n",
    "            errors = 0\n",
    "            for xi, yi in zip(x, y):\n",
    "                update = self.eta * (yi - self.predict(xi))\n",
    "                self.w += update * xi\n",
    "                self.b += update\n",
    "                errors += int(update != 0)\n",
    "            self.errors.append(errors)\n",
    "        return self\n",
    "    \n",
    "    def weighted_sum(self, x):\n",
    "        return np.dot(x, self.w) + self.b\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return np.where(self.weighted_sum(x) > 0.0, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8b85aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1])]\n",
      "Weights: [0.57088956 0.77413188 0.84864136]\n",
      "Bias: [0.44512815]\n",
      "Errors per epoch: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "perceptron = MyPerceptron(eta=0.1, epochs=100)\n",
    "\n",
    "# Train the Perceptron\n",
    "perceptron.fit(x, y)\n",
    "\n",
    "# Make predictions\n",
    "predictions = [perceptron.predict(xi) for xi in x]\n",
    "\n",
    "print(\"Predictions:\", predictions)\n",
    "print(\"Weights:\", perceptron.w)\n",
    "print(\"Bias:\", perceptron.b)\n",
    "print(\"Errors per epoch:\", perceptron.errors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
